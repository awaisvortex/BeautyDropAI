<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BeautyDrop Voice Agent - Test</title>
    <style>
        :root {
            --primary: #8b5cf6;
            --primary-dark: #7c3aed;
            --success: #10b981;
            --danger: #ef4444;
            --bg-dark: #0f0f1a;
            --bg-card: #1a1a2e;
            --text: #e2e8f0;
            --text-muted: #94a3b8;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-dark);
            color: var(--text);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem;
        }
        
        h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, var(--primary), #ec4899);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .subtitle {
            color: var(--text-muted);
            margin-bottom: 2rem;
        }
        
        .card {
            background: var(--bg-card);
            border-radius: 1rem;
            padding: 2rem;
            width: 100%;
            max-width: 500px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        }
        
        .status-bar {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1rem;
            background: rgba(139, 92, 246, 0.1);
            border-radius: 0.5rem;
            margin-bottom: 1.5rem;
        }
        
        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: var(--text-muted);
        }
        
        .status-dot.connecting { background: #fbbf24; animation: pulse 1s infinite; }
        .status-dot.connected { background: var(--success); }
        .status-dot.error { background: var(--danger); }
        .status-dot.speaking { background: var(--success); animation: pulse 0.5s infinite; }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        
        .status-text {
            font-size: 0.875rem;
            color: var(--text-muted);
        }
        
        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, var(--primary), var(--primary-dark));
            color: white;
            font-size: 2.5rem;
            cursor: pointer;
            margin: 2rem auto;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: 0 4px 15px rgba(139, 92, 246, 0.4);
        }
        
        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 25px rgba(139, 92, 246, 0.5);
        }
        
        .mic-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        
        .mic-button.active {
            background: linear-gradient(135deg, var(--danger), #dc2626);
            animation: pulse-shadow 1s infinite;
        }
        
        @keyframes pulse-shadow {
            0%, 100% { box-shadow: 0 4px 15px rgba(239, 68, 68, 0.4); }
            50% { box-shadow: 0 4px 30px rgba(239, 68, 68, 0.6); }
        }
        
        .instructions {
            text-align: center;
            color: var(--text-muted);
            font-size: 0.875rem;
            margin-bottom: 1.5rem;
        }
        
        .transcript-container {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 0.5rem;
            padding: 1rem;
            max-height: 300px;
            overflow-y: auto;
            margin-top: 1.5rem;
        }
        
        .transcript-container h3 {
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--text-muted);
            margin-bottom: 0.75rem;
        }
        
        .message {
            padding: 0.5rem 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
        }
        
        .message:last-child {
            border-bottom: none;
        }
        
        .message .role {
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            margin-bottom: 0.25rem;
        }
        
        .message.user .role { color: #60a5fa; }
        .message.assistant .role { color: #34d399; }
        .message.system .role { color: #fbbf24; }
        
        .message .text {
            font-size: 0.875rem;
            line-height: 1.5;
        }
        
        .text-input-container {
            display: flex;
            gap: 0.5rem;
            margin-top: 1rem;
        }
        
        .text-input {
            flex: 1;
            padding: 0.75rem 1rem;
            border-radius: 0.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            background: rgba(0, 0, 0, 0.3);
            color: var(--text);
            font-size: 0.875rem;
        }
        
        .text-input:focus {
            outline: none;
            border-color: var(--primary);
        }
        
        .send-btn {
            padding: 0.75rem 1.5rem;
            border-radius: 0.5rem;
            border: none;
            background: var(--primary);
            color: white;
            font-weight: 500;
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .send-btn:hover {
            background: var(--primary-dark);
        }
        
        .send-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .config-section {
            margin-bottom: 1.5rem;
        }
        
        .config-section label {
            display: block;
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--text-muted);
            margin-bottom: 0.5rem;
        }
        
        .config-section input {
            width: 100%;
            padding: 0.75rem 1rem;
            border-radius: 0.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            background: rgba(0, 0, 0, 0.3);
            color: var(--text);
            font-size: 0.875rem;
        }
        
        .visualizer {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            height: 40px;
            margin: 1rem 0;
        }
        
        .visualizer-bar {
            width: 4px;
            height: 10px;
            background: var(--primary);
            border-radius: 2px;
            transition: height 0.1s;
        }
    </style>
</head>
<body>
    <h1>üéôÔ∏è BeautyDrop Voice Agent</h1>
    <p class="subtitle">Ask about salons, services, and prices</p>
    
    <div class="card">
        <div class="config-section">
            <label>WebSocket URL</label>
            <input type="text" id="wsUrl" value="ws://localhost:8004/ws/voice/" />
        </div>
        
        <div class="status-bar">
            <div class="status-dot" id="statusDot"></div>
            <span class="status-text" id="statusText">Click the microphone to start</span>
        </div>
        
        <div class="instructions">
            Press and hold the microphone button to speak,<br>
            or type a message below to test without audio.
        </div>
        
        <button class="mic-button" id="micButton" onclick="toggleMic()">
            üé§
        </button>
        
        <div class="visualizer" id="visualizer" style="display: none;">
            <div class="visualizer-bar"></div>
            <div class="visualizer-bar"></div>
            <div class="visualizer-bar"></div>
            <div class="visualizer-bar"></div>
            <div class="visualizer-bar"></div>
        </div>
        
        <div class="text-input-container">
            <input type="text" class="text-input" id="textInput" placeholder="Or type a message..." />
            <button class="send-btn" id="sendBtn" onclick="sendText()" disabled>Send</button>
        </div>
        
        <div class="transcript-container">
            <h3>Conversation</h3>
            <div id="transcript"></div>
        </div>
    </div>
    
    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let isRecording = false;
        let audioQueue = [];
        let isPlaying = false;
        
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const micButton = document.getElementById('micButton');
        const sendBtn = document.getElementById('sendBtn');
        const transcript = document.getElementById('transcript');
        const textInput = document.getElementById('textInput');
        const visualizer = document.getElementById('visualizer');
        
        function updateStatus(status, message) {
            statusDot.className = 'status-dot ' + status;
            statusText.textContent = message;
        }
        
        function addMessage(role, text) {
            const div = document.createElement('div');
            div.className = 'message ' + role;
            div.innerHTML = `
                <div class="role">${role}</div>
                <div class="text">${text}</div>
            `;
            transcript.appendChild(div);
            transcript.scrollTop = transcript.scrollHeight;
        }
        
        function connect() {
            const url = document.getElementById('wsUrl').value;
            updateStatus('connecting', 'Connecting...');
            
            ws = new WebSocket(url);
            
            ws.onopen = () => {
                updateStatus('connected', 'Connected - Ready to talk!');
                sendBtn.disabled = false;
                addMessage('system', 'Connected to voice agent');
            };
            
            ws.onclose = () => {
                updateStatus('', 'Disconnected');
                sendBtn.disabled = true;
                addMessage('system', 'Disconnected');
            };
            
            ws.onerror = (error) => {
                updateStatus('error', 'Connection error');
                console.error('WebSocket error:', error);
            };
            
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                handleMessage(data);
            };
        }
        
        function handleMessage(data) {
            console.log('Received:', data.type, data);
            
            switch (data.type) {
                case 'status':
                    if (data.status === 'connected') {
                        updateStatus('connected', data.message || 'Connected');
                    }
                    break;
                    
                case 'transcript':
                    addMessage(data.role, data.text);
                    break;
                    
                case 'audio':
                    // Queue audio for playback
                    playAudio(data.data);
                    break;
                    
                case 'error':
                    updateStatus('error', data.message);
                    addMessage('system', 'Error: ' + data.message);
                    break;
            }
        }
        
        // Audio queue for smooth playback
        let audioBufferQueue = [];
        let isPlayingAudio = false;
        let playbackAudioContext = null;
        
        async function playAudio(base64Audio) {
            try {
                // Initialize audio context if needed
                if (!playbackAudioContext) {
                    playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 24000
                    });
                }
                
                // Decode base64 to ArrayBuffer
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Convert PCM16 to Float32
                const pcm16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768;
                }
                
                // Add to queue
                audioBufferQueue.push(float32);
                
                // Start playing if not already
                if (!isPlayingAudio) {
                    playNextAudioChunk();
                }
                
            } catch (error) {
                console.error('Audio playback error:', error);
            }
        }
        
        function playNextAudioChunk() {
            if (audioBufferQueue.length === 0) {
                isPlayingAudio = false;
                updateStatus('connected', 'Ready');
                return;
            }
            
            isPlayingAudio = true;
            updateStatus('speaking', 'Speaking...');
            
            const float32 = audioBufferQueue.shift();
            
            // Create audio buffer and play
            const audioBuffer = playbackAudioContext.createBuffer(1, float32.length, 24000);
            audioBuffer.getChannelData(0).set(float32);
            
            const source = playbackAudioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(playbackAudioContext.destination);
            source.onended = playNextAudioChunk;
            source.start();
        }
        
        async function toggleMic() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                connect();
                return;
            }
            
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }
        
        let recordingStream = null;
        let recordingContext = null;
        
        async function startRecording() {
            try {
                recordingStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Create context at native sample rate (browser doesn't support 24000)
                recordingContext = new (window.AudioContext || window.webkitAudioContext)();
                const nativeSampleRate = recordingContext.sampleRate;
                console.log('Native sample rate:', nativeSampleRate);
                
                const source = recordingContext.createMediaStreamSource(recordingStream);
                const processor = recordingContext.createScriptProcessor(4096, 1, 1);
                
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Resample from native rate to 24000Hz
                    const targetSampleRate = 24000;
                    const ratio = nativeSampleRate / targetSampleRate;
                    const resampledLength = Math.floor(inputData.length / ratio);
                    const resampled = new Float32Array(resampledLength);
                    
                    for (let i = 0; i < resampledLength; i++) {
                        const srcIndex = Math.floor(i * ratio);
                        resampled[i] = inputData[srcIndex];
                    }
                    
                    // Convert Float32 to PCM16
                    const pcm16 = new Int16Array(resampled.length);
                    for (let i = 0; i < resampled.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, resampled[i] * 32768));
                    }
                    
                    // Send as base64
                    const uint8Array = new Uint8Array(pcm16.buffer);
                    let binary = '';
                    for (let i = 0; i < uint8Array.length; i++) {
                        binary += String.fromCharCode(uint8Array[i]);
                    }
                    const base64 = btoa(binary);
                    ws.send(JSON.stringify({ type: 'audio', data: base64 }));
                    
                    // Update visualizer
                    updateVisualizer(inputData);
                };
                
                source.connect(processor);
                processor.connect(recordingContext.destination);
                
                isRecording = true;
                micButton.classList.add('active');
                micButton.innerHTML = 'üî¥';
                visualizer.style.display = 'flex';
                updateStatus('connected', 'Listening...');
                
            } catch (error) {
                console.error('Microphone error:', error);
                updateStatus('error', 'Microphone access denied');
            }
        }
        
        function stopRecording() {
            isRecording = false;
            micButton.classList.remove('active');
            micButton.innerHTML = 'üé§';
            visualizer.style.display = 'none';
            updateStatus('connected', 'Processing...');
            
            // Clean up recording resources
            if (recordingStream) {
                recordingStream.getTracks().forEach(track => track.stop());
                recordingStream = null;
            }
            if (recordingContext) {
                recordingContext.close();
                recordingContext = null;
            }
            
            // Tell server to commit audio buffer and generate response
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'commit' }));
            }
        }
        
        function updateVisualizer(audioData) {
            const bars = visualizer.querySelectorAll('.visualizer-bar');
            const step = Math.floor(audioData.length / bars.length);
            
            bars.forEach((bar, i) => {
                const value = Math.abs(audioData[i * step]) * 100;
                bar.style.height = Math.max(10, Math.min(40, value)) + 'px';
            });
        }
        
        function sendText() {
            const text = textInput.value.trim();
            if (!text || !ws || ws.readyState !== WebSocket.OPEN) return;
            
            ws.send(JSON.stringify({ type: 'text', text: text }));
            addMessage('user', text);
            textInput.value = '';
        }
        
        // Enter key to send text
        textInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') sendText();
        });
        
        // Auto-connect on load
        // connect();
    </script>
</body>
</html>
